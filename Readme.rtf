{\rtf1\ansi\ansicpg1252\cocoartf2513
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 In finetuning:\
I tried initializing the weights  and bias with xavier initialization and it gave me good results around 54% on test dataset.\
\
In tried without initialization and it gave me 0.524 on dev and 0.527 on test.\
\
For the sake of simplicity I have kept it without initialization.\
\
Parameters(For sst dataset)\
learning rate: 1e-5\
rest all default values\
\
\
Parameters(For Cfimdb dataset):\
learning rate: 1e-5\
batch_size=20\
\
For xavier initialization:\
I have commented out the code in Bert Sent Classifier.\
Please feel free to run it.\
Please keep the batch size to 80 when using xavier initialization.\
\
While running the code from terminal please put \'97cuda 0. \
}